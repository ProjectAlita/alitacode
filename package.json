{
  "name": "alitacode",
  "displayName": "ELITEA Code",
  "description": "Your Virtual Coding Assistant, to help you write better code faster",
  "version": "0.4.1",
  "icon": "images/128x128.png",
  "publisher": "ProjectAlita",
  "engines": {
    "vscode": "^1.78.0"
  },
  "categories": [
    "Other",
    "Machine Learning"
  ],
  "activationEvents": [
    "onStartupFinished"
  ],
  "repository": "https://github.com/ProjectAlita/alitacode.git",
  "main": "./out/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "eliteacode.predict",
        "title": "Predict"
      },
      {
        "command": "eliteacode.createPrompt",
        "title": "Create Prompt"
      },
      {
        "command": "eliteacode.addContext",
        "title": "Extend Context"
      },
      {
        "command": "eliteacode.syncPrompts",
        "title": "Sync External Prompts"
      },
      {
        "command": "eliteacode.initAlita",
        "title": "Init"
      },
      {
        "command": "eliteacode.getAvailableAIModels",
        "title": "Get available AI models from the server"
      }
    ],
    "menus": {
      "editor/context": [
        {
          "when": "editorFocus && !editorReadonly",
          "submenu": "eliteacode.submenu",
          "group": "Elitea"
        }
      ],
      "eliteacode.submenu": [
        {
          "when": "editorHasSelection && editorFocus && !editorReadonly && eliteacode.init",
          "command": "eliteacode.predict"
        },
        {
          "when": "editorFocus && !editorReadonly && eliteacode.init && eliteacode.LocalPrompts",
          "command": "eliteacode.createPrompt"
        },
        {
          "when": "editorFocus && !eliteacode.init && eliteacode.LLMProvider != 'None'",
          "command": "eliteacode.initAlita"
        },
        {
          "when": "editorHasSelection && editorFocus && !editorReadonly && eliteacode.init && eliteacode.LocalPrompts",
          "command": "eliteacode.addContext"
        },
        {
          "when": "eliteacode.init && eliteacode.LLMProvider in eliteacode.ExtentablePlatforms",
          "command": "eliteacode.syncPrompts"
        }
      ]
    },
    "submenus": [
      {
        "id": "eliteacode.submenu",
        "label": "Elitea"
      }
    ],
    "keybindings": [
      {
        "command": "eliteacode.predict",
        "key": "ctrl+shift+r"
      }
    ],
    "configuration": [
      {
        "title": "Main Settings",
        "properties": {
          "eliteacode.LLMServerUrl": {
            "order": 1,
            "type": "string",
            "default": "",
            "description": "URL to LLM service provider"
          },
          "eliteacode.LLMAuthToken": {
            "order": 2,
            "type": "string",
            "default": "",
            "pattern": "(^[A-Za-z0-9-_]+\\.[A-Za-z0-9-_]+\\.[A-Za-z0-9-_]{86}$)",
            "patternErrorMessage": "Token has incorrect format"
          },
          "eliteacode.projectId": {
            "order": 3,
            "type": "number",
            "default": 1,
            "description": "Project Id in Carrier, ignored for OpenAI and AI Dial"
          },
          "eliteacode.displayType": {
            "order": 4,
            "type": "string",
            "default": "append",
            "enum": [
              "append",
              "split",
              "replace",
              "prepend"
            ],
            "description": "Select the default display mode for the predictions"
          },
          "eliteacode.verifySsl": {
            "order": 5,
            "label": "Verify SSL",
            "type": "boolean",
            "default": true,
            "description": "Verify LLM service provider certificate"
          },
          "eliteacode.enable": {
            "order": 6,
            "type": "boolean",
            "default": true,
            "description": "Enable/disable this extension"
          },
          "eliteacode.debug": {
            "order": 10,
            "type": "boolean",
            "default": false,
            "description": "Enable/disable debug mode"
          }
        }
      },
      {
        "title": "Integration Settings",
        "properties": {
          "eliteacode.selectIntegration": {
            "order": 1,
            "type": "string",
            "default": "Please use [Click here to select] button",
            "enum": [
              "Please use [Click here to select] button"
            ],
            "markdownDescription": "[Click here to select](command:eliteacode.getAvailableAIModels)"
          },
          "eliteacode.LLMModelName": {
            "order": 2,
            "type": "string",
            "default": "",
            "markdownDescription": "Model name used for local prompts, this is deployment name, and it can be different from case to case"
          },
          "eliteacode.integrationName": {
            "order": 3,
            "type": "string"
          },
          "eliteacode.integrationUid": {
            "order": 4,
            "type": "string",
            "default": "Integration UUID goes here",
            "description": "AI integration Id from Alita Backened, ignored for OpenAI"
          }
        }
      },
      {
        "title": "Advanced Settings",
        "properties": {
          "eliteacode.customModelSize": {
            "order": 1,
            "type": "number",
            "default": 4096,
            "description": "Type custom model's tokens size"
          },
          "eliteacode.maxTokens": {
            "order": 2,
            "label": "Max Tokens default value",
            "type": "number",
            "default": 1024,
            "minimum": 1,
            "maximum": 8096,
            "description": "Max tokens value for the model"
          },
          "eliteacode.temperature": {
            "order": 3,
            "label": "Temperature default value",
            "type": "number",
            "default": 0.8,
            "minimum": 0,
            "maximum": 1,
            "description": "Temperature value for the model"
          },
          "eliteacode.topK": {
            "order": 4,
            "label": "Top K default value",
            "type": "number",
            "default": 40,
            "minimum": 1,
            "maximum": 40,
            "description": "Top K value for the model"
          },
          "eliteacode.topP": {
            "order": 5,
            "label": "Top P default value",
            "type": "number",
            "default": 0.8,
            "minimum": 0,
            "maximum": 1,
            "description": "Top P value for the model"
          }
        }
      }
    ]
  },
  "scripts": {
    "lint": "prettier . && eslint .",
    "lint:fix": "prettier --write . && eslint --fix .",
    "compile": "node ./esbuild.js",
    "pretest": "npm run lint",
    "test": "node ./test/runTest.js",
    "esbuild-base": "esbuild ./extension.js --bundle --outfile=out/extension.js --external:vscode --format=cjs --platform=node",
    "esbuild": "npm run esbuild-base -- --sourcemap",
    "esbuild-watch": "npm run esbuild-base -- --sourcemap --watch",
    "prevsce": "npm run compile -- --minify",
    "vsce": "vsce package",
    "publish": "vsce publish",
    "prepare": "husky"
  },
  "dependencies": {
    "@azure/openai": "^1.0.0-beta.12",
    "@vscode/webview-ui-toolkit": "^1.4.0",
    "axios": "^1.6.8",
    "form-data": "^4.0.0",
    "squirrelly": "7.9.2",
    "yaml": "^2.4.1"
  },
  "devDependencies": {
    "@types/glob": "^8.1.0",
    "@types/mocha": "^10.0.1",
    "@types/node": "20.2.5",
    "@types/vscode": "^1.78.0",
    "@vscode/test-electron": "^2.3.2",
    "@vscode/vsce": "^2.25.0",
    "esbuild": "^0.19.12",
    "eslint": "^8.41.0",
    "eslint-config-prettier": "^8.8.0",
    "glob": "^8.1.0",
    "husky": "^9.1.7",
    "lint-staged": "^15.2.11",
    "mocha": "^10.2.0",
    "prettier": "^2.8.8",
    "typescript": "^4.1.6"
  }
}
